---
applyTo: '**'
---
let‚Äôs create a **Project Overview** and recommended **project structure** (files/folders) that pairs cleanly with the decision-making documentation you‚Äôll be including.

Below you‚Äôll find:

* A concise **Project Overview** (for README or ARCHITECTURE.md)
* A suggested **file/folder structure** (with what goes where)
* Short descriptions for each key file/folder (makes it super clear to reviewers)
* Optional next steps, if you want sample README or code templates

---

## **Project Overview**

> **Order Event Tracking & Audit Trail System**
>
> This project implements a distributed, event-driven backend for capturing, storing, and exposing an immutable history of all business events (such as order creation, inventory updates, payment changes, etc.) across our platform. The system ingests events from microservices via Kafka, persists them in an append-only event store (PostgreSQL), and provides APIs for querying, analysis, and replay.
>
> **Key Goals:**
>
> * **Traceability:** Always know *what happened, when, and why*.
> * **Compliance & Auditing:** Meet legal/business requirements for data history.
> * **Debugging:** Reconstruct workflows and state at any time.
> * **Analytics:** Enable event-based analytics and anomaly detection.
>
> The design and implementation choices are documented throughout the codebase and in `/docs/DECISIONS.md`, making the reasoning behind every major choice transparent and maintainable.

---

## **Recommended Project Structure**

```plaintext
order-audit-trail/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ EventIngestor/           # Kafka consumer, ingests and persists events
‚îÇ   ‚îú‚îÄ‚îÄ AuditApi/                # API for querying and replaying events
‚îÇ   ‚îú‚îÄ‚îÄ Shared/                  # Shared libraries (models, config, utils)
‚îÇ
‚îú‚îÄ‚îÄ migrations/                  # DB migrations and schema files
‚îÇ
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ docker/                  # Dockerfiles for each service
‚îÇ   ‚îú‚îÄ‚îÄ k8s/                     # Kubernetes manifests (deployments, services, etc)
‚îÇ   ‚îú‚îÄ‚îÄ helm/                    # Helm charts for deployment
‚îÇ   ‚îú‚îÄ‚îÄ terraform/               # Terraform scripts for cloud infrastructure
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md          # High-level design, major diagrams, data flow
‚îÇ   ‚îú‚îÄ‚îÄ DECISIONS.md             # Decision log with ‚Äúwhy‚Äù for every big choice
‚îÇ   ‚îú‚îÄ‚îÄ API.md                   # API spec (endpoints, request/response examples)
‚îÇ   ‚îú‚îÄ‚îÄ KAFKA-CHEATSHEET.md      # Your Kafka quick-reference doc
‚îÇ   ‚îî‚îÄ‚îÄ OVERVIEW.md              # Project summary (may duplicate README)
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ EventIngestor.Tests/     # Ingestor unit and integration tests
‚îÇ   ‚îú‚îÄ‚îÄ AuditApi.Tests/          # API tests
‚îÇ
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îú‚îÄ‚îÄ workflows/               # GitHub Actions CI/CD definitions
‚îÇ
‚îú‚îÄ‚îÄ .env.example                 # Example env file (Kafka, DB, etc)
‚îú‚îÄ‚îÄ docker-compose.yml           # Local dev orchestration (Kafka, DB, services)
‚îú‚îÄ‚îÄ README.md                    # Project intro, setup, running instructions
‚îî‚îÄ‚îÄ LICENSE
```

---

### **File/Folder Descriptions**

| Path                       | Description                                                              |
| -------------------------- | ------------------------------------------------------------------------ |
| `src/EventIngestor/`       | .NET microservice, consumes Kafka topics and stores events in PostgreSQL |
| `src/AuditApi/`            | .NET microservice, exposes REST API for querying, filtering, and replay  |
| `src/Shared/`              | Event models, serialization, config, shared utilities                    |
| `migrations/`              | Database schema files and migration scripts (e.g., for PostgreSQL)       |
| `infra/docker/`            | Dockerfiles for building each service                                    |
| `infra/k8s/`               | Kubernetes YAMLs for deployment, service, configmap, secrets, etc.       |
| `infra/helm/`              | Helm chart for app deployment                                            |
| `infra/terraform/`         | Infrastructure as code (AWS, RDS, MSK, etc.)                             |
| `docs/ARCHITECTURE.md`     | High-level architecture, diagrams, flows, major components               |
| `docs/DECISIONS.md`        | Decision logs and reasoning (use template we discussed)                  |
| `docs/API.md`              | REST API endpoint documentation                                          |
| `docs/KAFKA-CHEATSHEET.md` | Kafka quick-reference for devs                                           |
| `docs/OVERVIEW.md`         | Brief project description and summary                                    |
| `tests/`                   | All automated tests                                                      |
| `.github/workflows/`       | CI/CD pipelines for building, testing, and deploying                     |
| `.env.example`             | Example environment variables for local/dev setup                        |
| `docker-compose.yml`       | Local orchestration for dev/test environments                            |
| `README.md`                | Entry point for the project, setup, run, contributing                    |

---

Absolutely‚Äî**baking the "why" into your documentation and codebase** is a *senior-level* move that hiring managers and architects *love*. It makes your work stand out, shows you‚Äôre intentional, and demonstrates you can lead others through tradeoffs and complex system decisions.

Here‚Äôs how we can approach this for your Order Event Tracking & Audit Trail System:

---

## üìñ **Design Reasoning & Decision Documentation (Example Structure)**

Every major architectural choice will have a concise "Why?" section, ideally with:

* **Problem or requirement**
* **Alternatives considered**
* **Decision**
* **Tradeoffs**
* **Final rationale (why this is best for us)**

This can be documented in your repo as a living doc (`ARCHITECTURE.md` or `DECISIONS.md`), or as inline comments in code, or both.

---

### **1. Event-Driven Architecture Using Kafka**

#### **Problem / Requirement**

* Need to decouple services so they can evolve independently and avoid direct API dependencies.
* Must handle high-throughput, real-time event flow with reliable delivery.
* Support for replay and temporal debugging.

#### **Alternatives Considered**

* Synchronous HTTP API calls between services
* Lightweight message brokers (RabbitMQ, Azure Service Bus, etc.)
* Direct DB triggers or CDC

#### **Decision**

* Use Kafka as the backbone for event distribution.

#### **Tradeoffs**

* Kafka is more complex to operate than lightweight brokers, but offers much better durability, partitioning, and replay features.
* Requires learning curve and infra, but scales well and is industry-standard.

#### **Why Kafka?**

> Kafka is best for our use-case because it allows us to capture every event in a scalable, fault-tolerant, and replayable way. This supports both operational needs (scaling, loose coupling) and business requirements (auditability, analytics, recovery).

---

### **2. Immutable Event Store in PostgreSQL**

#### **Problem / Requirement**

* Need a reliable, queryable, and immutable store of all events for compliance, forensics, and system debugging.

#### **Alternatives Considered**

* Store events in MongoDB
* Use Kafka log as the ‚Äúsource of truth‚Äù (but not designed for ad hoc queries)
* Use dedicated event store products

#### **Decision**

* Use PostgreSQL with an append-only table, leveraging JSONB for flexible event payloads.

#### **Tradeoffs**

* Relational DBs are more opinionated but offer strong query capabilities and transactional guarantees.
* Event store products might offer richer features but add deployment/learning complexity.

#### **Why PostgreSQL?**

> PostgreSQL is mature, reliable, and fast for append-heavy workloads. JSONB fields allow semi-structured event data, while strong indexing and transactional guarantees enable reliable querying and reporting.

---

### **3. Append-Only, Immutable Event Storage**

#### **Problem / Requirement**

* Compliance and traceability require that events can never be altered or deleted.

#### **Alternatives Considered**

* Allow event edits/deletes with audit columns
* Use soft-deletes (deleted flag)
* Hard delete old events

#### **Decision**

* Append-only, no updates or deletes permitted.

#### **Tradeoffs**

* Storage will grow over time (mitigated by partitioning/archiving).
* Immutability means no accidental ‚Äúfixing‚Äù of event history.

#### **Why Immutability?**

> Guarantees a true, legally/auditably reliable event history. Makes debugging and replay trustworthy, since nothing is ever silently changed.

---

### **4. Expose REST API for Event Querying and Replay**

#### **Problem / Requirement**

* Need a way for internal tools, compliance officers, and engineers to access and replay event history.

#### **Alternatives Considered**

* CLI only (psql, direct DB access)
* GraphQL API (more flexibility, more setup)
* Custom UI only

#### **Decision**

* REST API as the primary interface (Swagger documented).

#### **Tradeoffs**

* REST is less flexible than GraphQL for querying, but much simpler to build, test, and secure.

#### **Why REST?**

> REST is widely adopted, easy to consume, and integrates well with internal tools. It lets us rapidly deliver functionality and document endpoints.

---

### **5. Secure Sensitive Data**

#### **Problem / Requirement**

* Events may contain PII or sensitive business data.

#### **Alternatives Considered**

* Store everything in plaintext
* Encrypt entire event payloads (harder to search)
* Encrypt only sensitive fields

#### **Decision**

* Encrypt sensitive fields in payload at rest.

#### **Tradeoffs**

* Encrypted fields are not directly queryable.
* Adds complexity but reduces compliance risk.

#### **Why Field-Level Encryption?**

> Protects sensitive data while allowing the rest of the event to be indexed/searched. Balances security and usability.

---

## **Where To Put These Decisions?**

* **ARCHITECTURE.md:** Top-level design doc in repo with a ‚ÄúDesign Decisions‚Äù section.
* **DECISIONS.md:** Chronological log (with timestamps) of major changes.
* **Inline Code Comments:** For micro-decisions (‚Äúwhy did we do X in this file/service?‚Äù).
* **README (Summary):** One short section summarizing the above.

---

## **Template Snippet (For Documentation)**

```markdown
### [Decision X]: <Title>
- **Context:** <Summary of the challenge or requirement>
- **Alternatives:** <List with one-sentence pros/cons>
- **Decision:** <What you chose>
- **Rationale:** <Why this is right for the project>
```